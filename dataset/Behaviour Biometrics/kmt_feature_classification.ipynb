{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kmt_feature_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Xa4cDu6X4zDV",
        "SvZ28x_T-uv0",
        "Qpf1hWCtjuyk",
        "AteSUxqm4Ci2",
        "TzG3thuYkoea"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INSTRUCTIONS"
      ],
      "metadata": {
        "id": "Xa4cDu6X4zDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This file is designed to run with minimal user input. The code is divided into multiple steps and the user must execute the steps sequentially to produce results. \n",
        "\n",
        "* **Section 1**: downloads the dataset automatically\n",
        "* **Section 2**: imports all necessary libraries\n",
        "* **Section 3**: creates all the necessary methods for experiments\n",
        "* **Section 4**: executes the experiments to produce results\n",
        "* **Section 5**: visualises the results"
      ],
      "metadata": {
        "id": "RVWLt1G88K8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1 - Download Dataset\n"
      ],
      "metadata": {
        "id": "SvZ28x_T-uv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloads dataset from repository, unzips and mounts to google drive"
      ],
      "metadata": {
        "id": "WTbFW6Zm4p9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "dataset_name = 'behaviour_biometrics_dataset'\n",
        "\n",
        "dataset_url = 'https://drive.google.com/file/d/1t1yGjyO6hwAaYvlO_Chu0jgRAf8oVqAF/view?usp=sharing'\n",
        "\n",
        "dataset_url4wget = 'https://docs.google.com/uc?export=download&id=1t1yGjyO6hwAaYvlO_Chu0jgRAf8oVqAF'\n",
        "\n",
        "!wget -r --no-check-certificate \"$dataset_url4wget\" -O $dataset_name\".zip\"\n",
        "!ls\n",
        "\n",
        "!unzip  $dataset_name\".zip\"\n",
        "!ls"
      ],
      "metadata": {
        "id": "rqWwDYOH9KuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2 - Libraries\n"
      ],
      "metadata": {
        "id": "Qpf1hWCtjuyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports the key libraries used within this .IPYNB file."
      ],
      "metadata": {
        "id": "QdvhZROd4Lbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import json\n",
        "import pandas as pd\n",
        "import math"
      ],
      "metadata": {
        "id": "d0A79oQpkXcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3 - Core Methods"
      ],
      "metadata": {
        "id": "AteSUxqm4Ci2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executes the methods necessary to run experiments"
      ],
      "metadata": {
        "id": "6HccAHVJ5JRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERTS DICTIONARIES TAKEN FROM .JSON FILES INTO DATAFRAMES FOR THE KEY EVENTS\n",
        "def dict_key_conversion(data):\n",
        "    temp_df = pd.DataFrame(columns=['test_number', 'dwell_time', 'flight_time', 'key_pressed'])\n",
        "    temp_flight_df = pd.DataFrame(columns=['test_number', 'flight_time', 'key_released'])\n",
        "\n",
        "    temp_df_count = 0 # indicates which row of the df the next row of data should be appeneded into\n",
        "    temp_flight_df_count = 0\n",
        "\n",
        "    for i in range(1, 11): # loops through each of the tests in true_data\n",
        "        k_data = data['test_'+str(i)]['key_events']\n",
        "        # removes tabs from the data, as kivy, which is the library used for data collection, doesn't register tab releases, only presses\n",
        "        tabless_k_data = []\n",
        "        for k in k_data:\n",
        "            if k['Key'] != 'tab':\n",
        "                tabless_k_data.append(k)\n",
        "\n",
        "        count = 0 #counter for how many iterations into the for loop it is\n",
        "        f_count = 0 #counter for how many iterations into the loop the flight section has done\n",
        "        prev_key_press = 0\n",
        "        prev_key_release = 0\n",
        "        for j in tabless_k_data:\n",
        "            if j['Event'] == 'pressed': # THIS EXECUTES TO FIND THE DWELL TIME\n",
        "                flight_impute = 0 # imputes flight time as 0 for now, as there are instances of key presses not having releases at the end of the test\n",
        "                key_id = j['Key'] # this is what the actual key that is being pressed/released is\n",
        "                key_press_time = j['Epoch'] # the epoch time of the key press\n",
        "                key_release = False # is true when the release of the key has been found\n",
        "                cont_count = 1 # keeps track of counting from the current key press, as it loops from \n",
        "\n",
        "                while key_release == False: # continues \n",
        "                    c = cont_count + count\n",
        "                    start_row = tabless_k_data[count]\n",
        "                    next_row = tabless_k_data[c]\n",
        "                    # executes if the row is the release of the key that was pressed, and exits the while loop\n",
        "                    if next_row['Key'] == key_id and next_row['Event'] == 'released':\n",
        "                        key_release_time = next_row['Epoch']\n",
        "                        dwell_time = float(key_release_time) - float(key_press_time)\n",
        "                        key_release = True\n",
        "                    # executes if the next row is a press event for a different key\n",
        "                    elif next_row['Key'] != key_id and next_row['Event'] == 'pressed':\n",
        "                        cont_count += 1\n",
        "                    elif next_row['Key'] != key_id and next_row['Event'] == 'released':\n",
        "                        cont_count += 1\n",
        "                    else:\n",
        "                        key_release = True\n",
        "                        dwell_time = 0\n",
        "                        key_release_time = start_row['Epoch']\n",
        "\n",
        "                temp_df.loc[temp_df_count] = [i, dwell_time, flight_impute, key_id]\n",
        "\n",
        "                prev_key_press = key_press_time\n",
        "                prev_key_release = key_release_time\n",
        "                temp_df_count += 1\n",
        "\n",
        "            count += 1\n",
        "\n",
        "            if j['Event'] == 'released': # THIS EXECUTES TO FIND THE FLIGHT TIME\n",
        "                key_id = j['Key']\n",
        "                f_cont_count = 1\n",
        "                flight_time = []\n",
        "                flight_found = False\n",
        "                while flight_found == False:\n",
        "                    f_c = f_count + f_cont_count\n",
        "                    if f_c < len(tabless_k_data):\n",
        "                        next_row = tabless_k_data[f_c]\n",
        "                        if next_row['Event'] == 'pressed' and next_row['Key'] != key_id:\n",
        "                            flight_time = float(next_row['Epoch']) - float(j['Epoch'])\n",
        "                            temp_flight_df.loc[temp_flight_df_count] = [i, flight_time, key_id]\n",
        "                            temp_flight_df_count += 1\n",
        "                            flight_found = True\n",
        "                        f_cont_count += 1\n",
        "                    else:\n",
        "                        flight_found = True\n",
        "            f_count += 1\n",
        "\n",
        "    # Now merges the flight time df with the rest of the features\n",
        "    for i in range(1, 11):\n",
        "        fh_count = 0\n",
        "        flight_hold = []\n",
        "        for j in temp_flight_df.index:\n",
        "            if temp_flight_df.at[j, 'test_number'] == i:\n",
        "                flight_hold.append(temp_flight_df.at[j, 'flight_time'])\n",
        "        fh_count = 0\n",
        "\n",
        "        for j in temp_df.index:\n",
        "            if temp_df.at[j, 'test_number'] == i and fh_count < len(flight_hold):\n",
        "                temp_df.at[j, 'flight_time'] = flight_hold[fh_count]\n",
        "                fh_count += 1\n",
        "\n",
        "    true_k_df = temp_df\n",
        "    return true_k_df"
      ],
      "metadata": {
        "id": "mpYGKt2m6qNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERTS DICTIONARIES TAKEN FROM .JSON FILES INTO DATAFRAMES FOR THE MOUSE EVENTS\n",
        "def get_distance(a, b): # method used to calculate distance between two coordinates\n",
        "    distance = math.sqrt(((a[0] - b[0]) ** 2) + ((a[1] - b[1]) ** 2))\n",
        "    return distance\n",
        "\n",
        "def dict_mouse_conversion(data):\n",
        "    m_df = pd.DataFrame(columns = ['test_number', 'movement_id', 'trajectory', 'single_coor'])\n",
        "    row_count = 0\n",
        "    for i in range(1, 11):\n",
        "        m_data = data['test_'+str(i)]['mouse_events']\n",
        "        m_movements = []\n",
        "        for j in m_data[:len(m_data)-1]:\n",
        "            if j['Event'] == 'movement':\n",
        "                m_movements.append(j)\n",
        "        \n",
        "        # creates dictionary that passes all the movement coordinates to the each movement ID in the test\n",
        "        movement_coor_dict = {}\n",
        "        for j in m_movements:\n",
        "            movement_coor_dict[j['Movement ID']] = [] \n",
        "        for j in m_movements:\n",
        "            movement_coor_dict[j['Movement ID']].append(j['Coordinates'])\n",
        "\n",
        "        # calculates the overall trajectory length for each of the movement IDs   \n",
        "        for j in movement_coor_dict:\n",
        "            coor_list = movement_coor_dict[j]\n",
        "            motion_start = False\n",
        "            trajectory = 0\n",
        "            if len(coor_list) > 1:\n",
        "                trajectory_list = []\n",
        "                if motion_start == True:\n",
        "                    motion_start = False\n",
        "                else:\n",
        "                    count = 0\n",
        "                    for k in coor_list:\n",
        "                        trajectory_list.append(get_distance(coor_list[count-1], coor_list[count]))\n",
        "                        count += 1\n",
        "                    movement_id = j\n",
        "                    trajectory = sum(trajectory_list)\n",
        "                    single_coor = False\n",
        "            else:\n",
        "                movement_id = 1\n",
        "                trajectory_list = [0]\n",
        "                trajectory = 0\n",
        "                single_coor = False\n",
        "            m_df.loc[row_count] = [i, movement_id, trajectory, single_coor]\n",
        "            row_count += 1\n",
        "    m_df = m_df.sort_values(by=['test_number', 'movement_id'])\n",
        "    \n",
        "    for j in m_df['single_coor'].tolist():\n",
        "        if j == True:\n",
        "            m_df = movement_df.drop[count] \n",
        "        count += 1\n",
        "    m_df = m_df.reset_index(drop=True)\n",
        "    return m_df"
      ],
      "metadata": {
        "id": "6UvNRM6A7MuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GENERATES FEATURES FOR EACH TEST FROM THE DFS GENERATED IN THE PREVIOUS TWO CELLS\n",
        "def feature_gen(k_data, m_data):\n",
        "    columns = ['dwell_avg', 'flight_avg', 'traj_avg']\n",
        "    \n",
        "    df = pd.DataFrame(columns=columns)\n",
        "    \n",
        "    # for loop calculates average value for the dwell time, flight time and trajectory for each test\n",
        "    for i in range(1, 11):\n",
        "        dwell_list = []\n",
        "        flight_list = []\n",
        "        traj_list = []\n",
        "        for j in k_data.index:\n",
        "            if k_data.at[j, 'test_number'] == i:\n",
        "                dwell_list.append(k_data.at[j, 'dwell_time'])\n",
        "                flight_list.append(k_data.at[j, 'flight_time'])\n",
        "        for j in m_data.index:\n",
        "            if m_data.at[j, 'test_number'] == i:\n",
        "                traj_list.append(m_data.at[j, 'trajectory'])\n",
        "        \n",
        "        dwell_list = [j for j in dwell_list if j != 0]\n",
        "        flight_list = [j for j in flight_list if j != 0]\n",
        "        traj_list = [j for j in traj_list if j != 0]\n",
        "                \n",
        "        dwell_avg = sum(dwell_list)/len(dwell_list)\n",
        "        flight_avg = sum(flight_list)/len(dwell_list)\n",
        "        traj_avg = sum(traj_list)/len(traj_list)\n",
        "        \n",
        "            \n",
        "        agg_data = [dwell_avg, flight_avg, traj_avg]\n",
        "        \n",
        "        df.loc[i] = agg_data\n",
        "    return df"
      ],
      "metadata": {
        "id": "JkaYpvW47wSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4 - Experiments & Results\n",
        "\n"
      ],
      "metadata": {
        "id": "wL6VtTBy6xpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loads the raw .json files from google drive, generates features for ML classification task, and evaluates the models. "
      ],
      "metadata": {
        "id": "20KznIZF6TMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Temporary list storage for visualisation\n",
        "acc_list = []\n",
        "fm_list = []\n",
        "# RUNS THE MODEL ON EACH OF THE USER'S DATA\n",
        "\n",
        "for i in range(1, 89):\n",
        "    # stores each of the true data as dictionaries\n",
        "    user_number = i \n",
        "    user_number = str(user_number).zfill(4)\n",
        "    f = open('behaviour_biometrics_dataset/raw_kmt_dataset/raw_kmt_user_' + user_number + '.json') # loads 1 of the 88 tests from drive\n",
        "    data = json.load(f)\n",
        "    user_details = data['details'] # stores the fabricated card details entered for the user\n",
        "    true_data = data['true_data'] # stores the true data of the .json file\n",
        "    false_data = data ['false_data']\n",
        "    #----------------------------------\n",
        "    true_k_df = dict_key_conversion(true_data) # gets the key events from the json files\n",
        "    false_k_df = dict_key_conversion(false_data)\n",
        "\n",
        "    true_m_df = dict_mouse_conversion(true_data) # gets the mouse events from the json files\n",
        "    false_m_df = dict_mouse_conversion(false_data)\n",
        "    #----------------------------------\n",
        "    true_df = feature_gen(true_k_df, true_m_df) # gets the average dwell, flight and traj for each test\n",
        "    false_df = feature_gen(false_k_df, false_m_df)\n",
        "    true_df['label'] = 1 # adds true or false label to the df for the ML algorithm, 1 == true, 0 == false\n",
        "    false_df['label'] = 0\n",
        "    final_df = pd.concat([true_df, false_df])\n",
        "    final_df = final_df.reset_index(drop=True) # final df that will be used within the ML algorithm\n",
        "    #----------------------------------\n",
        "    y = final_df['label'].tolist() # carries out the train test split and the ML prediction\n",
        "    X = final_df.drop(['label'], axis=1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "    clf = tree.DecisionTreeClassifier()\n",
        "    clf.fit(X_train, y_train)\n",
        "    predicted_labels = clf.predict(X_test)\n",
        "    clf_rep = classification_report(y_test, predicted_labels, output_dict=True)\n",
        "    acc = clf_rep['accuracy']\n",
        "    fm = clf_rep['weighted avg']['f1-score']\n",
        "    print('User', i)\n",
        "    print('Target Labels', y_test)\n",
        "    print('Predicted Labels', predicted_labels)\n",
        "    print('Accuracy:', acc)\n",
        "    print('Fm:', fm)\n",
        "    print('----------------------------')\n",
        "    \n",
        "    acc_list.append(acc)\n",
        "    fm_list.append(fm)\n",
        "\n",
        "\n",
        "\n",
        "final_acc = sum(acc_list)/len(acc_list)\n",
        "final_fm = sum(fm_list)/len(fm_list)\n",
        "\n",
        "\n",
        "print(' ')\n",
        "print('###########################')\n",
        "print('##########RESULTS##########')\n",
        "print('###########################')\n",
        "print('Accuracy:', final_acc)\n",
        "print('F-Measure:', final_fm)"
      ],
      "metadata": {
        "id": "1LYQooA18PlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5 - Visualisation\n"
      ],
      "metadata": {
        "id": "TzG3thuYkoea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provides visual representation of the experimental data (frame) and results"
      ],
      "metadata": {
        "id": "sIDY0bBc7g5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df # displays the last df that was passed to the ML algorithm"
      ],
      "metadata": {
        "id": "8XnAX5yUA2-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list.sort()\n",
        "fm_list.sort()\n",
        "ind_class = []\n",
        "for i in range(1, 89):\n",
        "  ind_class.append(i)\n",
        "\n",
        "f = plt.figure(figsize=(14, 7))\n",
        "\n",
        "ax = f.add_subplot(121)\n",
        "ax.plot(ind_class, acc_list, linewidth=3)\n",
        "ax.set_title('(a) Accuraccy Distribution', fontsize=19)\n",
        "ax.set_xlabel('Individual Classifiers', fontsize=17)\n",
        "ax.set_ylim(-.1, 1.1)\n",
        "\n",
        "ax2 = f.add_subplot(122)\n",
        "ax2.plot(ind_class, fm_list, linewidth=3)\n",
        "ax2.set_title('(b) F-Measure Distribution', fontsize=19)\n",
        "ax2.set_xlabel('Individual Classifiers', fontsize=17)\n",
        "ax2.set_ylim(-.1, 1.1)"
      ],
      "metadata": {
        "id": "ypK_jEqOvQ5S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}